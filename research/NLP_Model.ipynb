{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":21824,"status":"ok","timestamp":1691439256554,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"ylOysuy1oWoK"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from wordcloud import WordCloud, STOPWORDS\n","%matplotlib inline\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from textblob import TextBlob\n","\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from gensim import corpora, models\n","import gensim\n","\n","import string\n","import re\n","import spacy\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn import metrics\n","\n","from sklearn.svm import LinearSVC\n","from sklearn.tree import ExtraTreeClassifier\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","\n","from sklearn.decomposition import TruncatedSVD,PCA\n","from sklearn.preprocessing import normalize,Normalizer\n","from sklearn.pipeline import make_pipeline\n","\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score\n","from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n","\n","from sklearn.decomposition import LatentDirichletAllocation as LDA\n","\n","from gensim.models import Word2Vec, KeyedVectors\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","pd.set_option('display.max_columns', None)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26874,"status":"ok","timestamp":1691439363005,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"uGzWZHz2ph3Z","outputId":"a35dd21e-9866-47c7-9dda-ca9870edae6b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["# Mounting Colab notebook with Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1691439363006,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"zWLsVEVGph1E"},"outputs":[],"source":["# Setting up the Dataset path\n","dataset_path = '/content/drive/MyDrive/Colab Notebooks/NLP_Model'"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6564,"status":"ok","timestamp":1691439369564,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"ScNwuY_1phyi"},"outputs":[],"source":["data = pd.read_excel(dataset_path+'/Womens Clothing Reviews Data.xlsx')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1691439369565,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"xA-oW-W8Ril1"},"outputs":[],"source":["data.columns = data.columns.str.replace(' ', '_')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WLmrMcODphv4"},"outputs":[],"source":["data.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z3R1WfY9phtK"},"outputs":[],"source":["data.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GkeEkaMmphqi"},"outputs":[],"source":["data.isna().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SGaTEGo4phn5"},"outputs":[],"source":["data['Category'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dUYwvgjbphlL"},"outputs":[],"source":["data['Subcategory1'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gjBZlKXvphd6"},"outputs":[],"source":["## city wise contribution\n","plt.figure(figsize=(12,8))\n","city = (data['Location'].value_counts()/data['Location'].count())*100\n","city = city.sort_index(ascending=True)\n","explode = [0.1 if city[i] == max(city) else 0 for i in city.index]\n","colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']\n","plt.pie(city, labels=city.index, colors=colors, autopct='%1.1f%%', startangle=140, explode=explode)\n","centre_circle = plt.Circle((0, 0), 0.70, fc='white')\n","fig = plt.gcf()\n","fig.gca().add_artist(centre_circle)\n","plt.legend(labels=city.index, loc=\"upper right\")\n","plt.title(\"City Wise Contribution\")\n","plt.axis('equal')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r-l7dJjOphbM"},"outputs":[],"source":["## Category wise contribution\n","explode = [0.1 if cat[i] == max(cat) else 0 for i in cat.index]\n","plt.figure(figsize=(12,8))\n","cat = (data['Category'].value_counts()/data['Category'].count())*100\n","cat = cat.sort_index(ascending=True)\n","colors = ['#ff9999', '#66b3ff', '#99ff99']\n","plt.pie(cat, labels=cat.index, colors=colors, autopct='%1.1f%%', startangle=140, explode=explode)\n","centre_circle = plt.Circle((0, 0), 0.70, fc='white')\n","fig = plt.gcf()\n","fig.gca().add_artist(centre_circle)\n","plt.legend(labels=cat.index, loc=\"upper right\")\n","plt.title(\"Category Wise Contribution\")\n","plt.axis('equal')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MqpQH6fFphYi"},"outputs":[],"source":["## Sub_Category wise contribution\n","plt.figure(figsize=(12,8))\n","sub_cat = (data['Subcategory1'].value_counts()/data['Subcategory1'].count())*100\n","sub_cat = sub_cat.sort_index(ascending=True)\n","explode = [0.1 if sub_cat[i] == max(sub_cat) else 0 for i in sub_cat.index]\n","colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99', '#c2c2f0', '#ffb3e6', '#ff9999']\n","plt.pie(sub_cat, labels=sub_cat.index, colors=colors, autopct='%1.1f%%', startangle=140, explode=explode)\n","centre_circle = plt.Circle((0, 0), 0.70, fc='white')\n","fig = plt.gcf()\n","fig.gca().add_artist(centre_circle)\n","plt.legend(labels=sub_cat.index, loc=\"upper right\")\n","plt.title(\"Sub_category Wise Contribution\")\n","plt.axis('equal')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FlVHpGnvDqIo"},"outputs":[],"source":["## Rating wise contribution\n","plt.figure(figsize=(12,8))\n","info = (data['Rating'].value_counts()/data['Rating'].count())*100\n","info = info.sort_index(ascending=True)\n","explode = [0.1 if info[i] == max(info) else 0 for i in info.index]\n","colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99', '#c2c2f0', '#ffb3e6']\n","plt.pie(info, labels=info.index, colors=colors, autopct='%1.1f%%', startangle=140, explode=explode)\n","centre_circle = plt.Circle((0, 0), 0.70, fc='white')\n","fig = plt.gcf()\n","fig.gca().add_artist(centre_circle)\n","plt.legend(labels=info.index, loc=\"upper right\")\n","plt.title(\"Rating Wise Contribution\")\n","plt.axis('equal')\n","plt.show()"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":818,"status":"ok","timestamp":1691439411044,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"Ve42CgQGphTc"},"outputs":[],"source":["## Dropping columns which are not needed\n","cols = ['Product_ID','SubCategory2','Review_Title']\n","data.drop(columns=cols, inplace=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1691439411893,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"Bnn686NMphLt"},"outputs":[],"source":["# creating a column by the name Age_group & dividing the customers accordingly\n","bins = [0, 40, 60, 99]\n","labels = ['Youth', 'Adult', 'Senior']\n","data['Age_group'] = pd.cut(data.Customer_Age, bins, labels = labels,include_lowest = True)\n","\n","## Dropping Age column as we have Age_group now\n","data.drop(columns='Customer_Age',inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-1pCbx57phI2"},"outputs":[],"source":["## Age wise contribution\n","plt.figure(figsize=(12,8))\n","Age = (data['Age_group'].value_counts()/data['Age_group'].count())*100\n","Age = Age.sort_index(ascending=True)\n","explode = [0.1 if Age[i] == max(Age) else 0 for i in Age.index]\n","colors = ['#ff9999', '#66b3ff', '#99ff99']\n","plt.pie(Age, labels=Age.index, colors=colors, autopct='%1.1f%%', startangle=140, explode=explode)\n","centre_circle = plt.Circle((0, 0), 0.70, fc='white')\n","fig = plt.gcf()\n","fig.gca().add_artist(centre_circle)\n","plt.legend(labels=Age.index, loc=\"upper right\")\n","plt.title(\"Age Wise Contribution\")\n","plt.axis('equal')\n","plt.show()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":772,"status":"ok","timestamp":1691439416938,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"N5TxrCgtphDi"},"outputs":[],"source":["def replace_null(df):\n","    # Get a list of columns with the object data type\n","    object_columns = df.select_dtypes(include='object').columns.tolist()\n","\n","    # Iterate through each object column and replace null values with mode\n","    for col in object_columns:\n","        mode_value = df[col].mode().iloc[0]\n","        df[col].fillna(mode_value, inplace=True)\n","\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QAweGbCxphBB"},"outputs":[],"source":["replace_null(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yNuiRUzOpg-R"},"outputs":[],"source":["data.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xrJLFPwPpg2i"},"outputs":[],"source":["nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","\n","\n","nlp = spacy.load('en_core_web_sm')\n","\n","def text_preprocessing(text):\n","    # Remove leading and trailing whitespaces\n","    text = text.strip()\n","\n","    # Convert to lowercase\n","    text = text.lower()\n","\n","    # Remove digits and special characters using regular expression\n","    text = re.sub(r\"[-()\\\"#/@;:{}`+=~|._!?,'0-9]\", \"\", text)\n","\n","    # Tokenize the text using NLTK\n","    tokens = nltk.word_tokenize(text)\n","\n","    # Remove stop words using NLTK\n","    stop = set(nltk.corpus.stopwords.words('english'))\n","    stop1 = set(list(stop)+['always', 'go', 'got', 'could', 'also', 'get', 'us', 'even', 'i', 'm', 'would', 'do', 'go'])\n","    tokens = [token for token in tokens if token not in stop1]\n","\n","    # Correct spelling errors using TextBlob\n","    #corrected_tokens = [str(TextBlob(token).correct()) for token in tokens]\n","\n","    # Lemmatize using spaCy\n","    lemmatized_tokens = [token.lemma_ for token in nlp(\" \".join(tokens))]\n","\n","    # Remove duplicate words\n","    lemmatized_tokens = list(dict.fromkeys(lemmatized_tokens))\n","\n","    # Join the tokens back into a cleaned sentence\n","    cleaned_text = \" \".join(lemmatized_tokens)\n","\n","    return cleaned_text"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":316228,"status":"ok","timestamp":1691412165005,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"6DNkO2ftpgzx"},"outputs":[],"source":["data['Review_Text'] = data['Review_Text'].apply(lambda x: text_preprocessing(x))"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":7153,"status":"ok","timestamp":1691412172154,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"BSQJ4tNNpgwz"},"outputs":[],"source":["data['sentiment_score'] =  data.Review_Text.apply(lambda x: TextBlob(x).sentiment.polarity)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1691412172158,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"hdbcuc2TNLkD"},"outputs":[],"source":["data['sentiment'] = np.where(data.sentiment_score>0.2,'Positive',np.where(data.sentiment_score<-0.05, 'Negative', 'Neutral'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nMs5U0CCNLhe"},"outputs":[],"source":["pd.crosstab(data.Rating, data.sentiment)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":210829,"status":"ok","timestamp":1691412382977,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"pFTk0ECcNLfH"},"outputs":[],"source":["Positive_review = data.Review_Text[data.Rating>=4]\n","Positive_review = Positive_review.apply(lambda x: text_preprocessing(x))"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":62023,"status":"ok","timestamp":1691412444987,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"d96_PODwcicF"},"outputs":[],"source":["Negative_review = data.Review_Text[data.Rating<4]\n","Negative_review = Negative_review.apply(lambda x: text_preprocessing(x))"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1691412444988,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"Y55X7t8_ZcSg"},"outputs":[],"source":["stop = set(nltk.corpus.stopwords.words('english'))\n","stop1 = set(list(stop)+['always', 'go', 'got', 'could', 'also', 'get', 'us', 'even', 'i', 'm', 'would', 'do', 'go'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xqalm-RlNLcT"},"outputs":[],"source":["\n","colormap = 'viridis'\n","wordcloud =  WordCloud(\n","                    width=500, height=300,stopwords=stop1,\n","                    random_state = 123,max_words=200,colormap=colormap,\n","                    background_color = 'white', max_font_size = 75\n","                   ).generate(' '.join(Positive_review.astype(str)))\n","\n","%matplotlib inline\n","fig = plt.figure(figsize=(200,50))\n","plt.imshow(wordcloud, interpolation='bilinear')\n","plt.axis('off')\n","plt.title('Word Cloud of Positive Reviews', fontsize=100, pad=20)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Srx2KnsNLZr"},"outputs":[],"source":["colormap = 'viridis'\n","wordcloud =  WordCloud(\n","                    width=500, height=300,stopwords=stop1,\n","                    random_state = 123,max_words=200,colormap=colormap,\n","                    background_color = 'white', max_font_size = 75\n","                   ).generate(' '.join(Negative_review.astype(str)))\n","\n","%matplotlib inline\n","fig = plt.figure(figsize=(200,50))\n","plt.imshow(wordcloud, interpolation='bilinear')\n","plt.axis('off')\n","plt.title('Word Cloud of Negative reviews', fontsize=100, pad=20)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c9KiIITt8vx1"},"outputs":[],"source":["import plotly.graph_objects as go\n","\n","tab = pd.crosstab(index=data['Category'], columns=data['sentiment'])\n","\n","# Plotting the grouped bar chart using Plotly\n","fig = go.Figure()\n","\n","# Adding trace for each sentiment\n","sentiments = tab.columns\n","for sentiment in sentiments:\n","    fig.add_trace(go.Bar(\n","        x=tab.index,\n","        y=tab[sentiment],\n","        name=sentiment\n","    ))\n","\n","# Customizing the layout\n","fig.update_layout(\n","    title='Sentiment Counts by Category',\n","    xaxis_title='Category',\n","    yaxis_title='Count',\n","    barmode='group',  # Grouped bar chart\n","    bargap=0.2,       # Gap between bars in the same location coordinate\n","    bargroupgap=0.1,  # Gap between bars in different location coordinates\n",")\n","\n","# Display the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GVREmgOJ9LJG"},"outputs":[],"source":["tab_1 = pd.crosstab(index=data['Subcategory1'], columns=data['sentiment'])\n","\n","# Plotting the grouped bar chart using Plotly\n","fig = go.Figure()\n","\n","# Adding trace for each sentiment\n","sentiments = tab_1.columns\n","for sentiment in sentiments:\n","    fig.add_trace(go.Bar(\n","        x=tab_1.index,\n","        y=tab_1[sentiment],\n","        name=sentiment\n","    ))\n","\n","# Customizing the layout\n","fig.update_layout(\n","    title='Sentiment Counts by Subcategory',\n","    xaxis_title='Subcategory',\n","    yaxis_title='Count',\n","    barmode='group',  # Grouped bar chart\n","    bargap=0.2,       # Gap between bars in the same location coordinate\n","    bargroupgap=0.1,  # Gap between bars in different location coordinates\n",")\n","\n","# Display the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s8tAHAsR9LGA"},"outputs":[],"source":["tab_2 = pd.crosstab(index=data['Location'], columns=data['sentiment'])\n","\n","# Plotting the grouped bar chart using Plotly\n","fig = go.Figure()\n","\n","# Adding trace for each sentiment\n","sentiments = tab_2.columns\n","for sentiment in sentiments:\n","    fig.add_trace(go.Bar(\n","        x=tab_2.index,\n","        y=tab_2[sentiment],\n","        name=sentiment\n","    ))\n","\n","# Customizing the layout\n","fig.update_layout(\n","    title='Sentiment Counts by Loaction',\n","    xaxis_title='Location',\n","    yaxis_title='Count',\n","    barmode='group',\n","    bargap=0.2,\n","    bargroupgap=0.1,\n","  )\n","\n","# Display the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iem3eBFg9LDC"},"outputs":[],"source":["tab_3 = pd.crosstab(index=data['Channel'], columns=data['sentiment'])\n","\n","# Plotting the grouped bar chart using Plotly\n","fig = go.Figure()\n","\n","# Adding trace for each sentiment\n","sentiments = tab_3.columns\n","for sentiment in sentiments:\n","    fig.add_trace(go.Bar(\n","        x=tab_3.index,\n","        y=tab_3[sentiment],\n","        name=sentiment\n","    ))\n","\n","# Customizing the layout\n","fig.update_layout(\n","    title='Sentiment Counts by Channel',\n","    xaxis_title='Channel',\n","    yaxis_title='Count',\n","    barmode='group',\n","    bargap=0.2,\n","    bargroupgap=0.1,\n",")\n","\n","# Display the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OFBI-N7k9LAc"},"outputs":[],"source":["tab_4 = pd.crosstab(index=data['Age_group'], columns=data['sentiment'])\n","\n","# Plotting the grouped bar chart using Plotly\n","fig = go.Figure()\n","\n","# Adding trace for each sentiment\n","sentiments = tab_4.columns\n","for sentiment in sentiments:\n","    fig.add_trace(go.Bar(\n","        x=tab_4.index,\n","        y=tab_4[sentiment],\n","        name=sentiment\n","    ))\n","\n","# Customizing the layout\n","fig.update_layout(\n","    title='Sentiment Counts by Age_group',\n","    xaxis_title='Age_group',\n","    yaxis_title='Count',\n","    barmode='group',\n","    bargap=0.2,\n","    bargroupgap=0.1,\n",")\n","\n","# Display the plot\n","fig.show()"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1691412470628,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"wK93sZQC9K9V"},"outputs":[],"source":["vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}',\n","                             ngram_range=(1, 1 ),\n","                             min_df=1,\n","                             encoding='latin-1',\n","                             max_features=1000)\n","Positive_review_count = vect.fit_transform(Positive_review)\n","DTM_postive = pd.DataFrame(Positive_review_count.toarray(), columns = vect.get_feature_names_out())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-I7qOMuK9K5a"},"outputs":[],"source":["import plotly.graph_objects as go\n","word_freq = DTM_postive.apply(sum).nlargest(30).sort_values(ascending=False)\n","fig = go.Figure()\n","\n","fig.add_trace(go.Bar(\n","    x=word_freq.index,\n","    y=word_freq.values,\n","    marker_color='green',  # Set the color of the bars\n","))\n","\n","# Customize the layout\n","fig.update_layout(\n","    title=\"Top 30 Words by Frequency in positive Review\",\n","    xaxis_title=\"Words\",\n","    yaxis_title=\"Frequency\",\n","    xaxis_tickangle=-45,  # Rotate x-axis labels for better visibility\n",")\n","\n","# Show the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"11K-VSU3ODXk"},"outputs":[],"source":["vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}',\n","                             ngram_range=(1, 1 ),\n","                             min_df=1,\n","                             encoding='latin-1' ,\n","                             max_features=1000)\n","Negative_review_count = vect.fit_transform(Negative_review)\n","DTM_Negative = pd.DataFrame(Negative_review_count.toarray(), columns = vect.get_feature_names_out())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UnCyqc00ODUL"},"outputs":[],"source":["word_freq = DTM_Negative.apply(sum).nlargest(30).sort_values(ascending=False)\n","fig = go.Figure()\n","\n","fig.add_trace(go.Bar(\n","    x=word_freq.index,\n","    y=word_freq.values,\n","    marker_color='Red',  # Set the color of the bars\n","))\n","\n","# Customize the layout\n","fig.update_layout(\n","    title=\"Top 30 Words by Frequency in Negative Review\",\n","    xaxis_title=\"Words\",\n","    yaxis_title=\"Frequency\",\n","    xaxis_tickangle=-45,  # Rotate x-axis labels for better visibility\n",")\n","\n","# Show the plot\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"1Wh_tKhpMPZm"},"source":["## Binary Classification Model"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":725,"status":"ok","timestamp":1691416970640,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"Awr46Au2ODQl"},"outputs":[],"source":["## Getting x & y variables\n","x = data['Review_Text']\n","y = data['Recommend_Flag']"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1691412470630,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"04S5vF2UOwSg"},"outputs":[],"source":["## Splitting the data intp train & test\n","train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.3, random_state=123)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":273532,"status":"ok","timestamp":1691412744144,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"SfOu2cg_O7en"},"outputs":[],"source":["train_x = train_x.apply(lambda x: text_preprocessing(x))\n","test_x = test_x.apply(lambda x: text_preprocessing(x))"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":989,"status":"ok","timestamp":1691412745129,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"KF3pbbw2O7b4"},"outputs":[],"source":["TFIDF = TfidfVectorizer(analyzer='word',\n","                             token_pattern=r'\\w{1,}',\n","                             ngram_range=(1, 1 ),\n","                             min_df=5,\n","                             encoding='latin-1' ,\n","                             lowercase = True,\n","                             max_features=1000)\n","train_x_TFIDF = TFIDF.fit_transform(train_x)\n","test_x_TFIDF = TFIDF.transform(test_x)"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1691412745130,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"NWv8Ep62O7ZC"},"outputs":[],"source":["train_x_DTM = pd.DataFrame(train_x_TFIDF.toarray(), columns=TFIDF.get_feature_names_out())\n","test_x_DTM = pd.DataFrame(test_x_TFIDF.toarray(), columns=TFIDF.get_feature_names_out())"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1691412745130,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"JPlbFN4-RIAc"},"outputs":[],"source":["\n","def train_and_predict_models(train_x, train_y, test_x, test_y):\n","\n","    # Create the model list\n","    model_list = [\n","        ('Random Forest', RandomForestClassifier()),\n","        ('XG Boost', XGBClassifier()),\n","        ('Extra Trees', ExtraTreeClassifier()),\n","        ('Linear SVC', LinearSVC()),\n","        ('Naive Bayes', MultinomialNB()),\n","        ('KNN', KNeighborsClassifier())\n","    ]\n","\n","    results = {}\n","\n","    for model_name, model in model_list:\n","        print(f\"Training {model_name}...\")\n","        model.fit(train_x, train_y)\n","\n","        # Make predictions on training and testing data\n","        train_pred = model.predict(train_x)\n","        test_pred = model.predict(test_x)\n","\n","        # Calculate accuracy for training and testing data\n","        train_accuracy = accuracy_score(train_y, train_pred)\n","        test_accuracy = accuracy_score(test_y, test_pred)\n","\n","        results[model_name] = {\n","            'train_accuracy': train_accuracy,\n","            'test_accuracy': test_accuracy\n","        }\n","\n","    return results"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":137025,"status":"ok","timestamp":1691412882147,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"ykMSsYzcRH9U","outputId":"bd4dc415-075b-4b8e-edc4-f539a53aea96"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Random Forest...\n","Training XG Boost...\n","Training Extra Trees...\n","Training Linear SVC...\n","Training Naive Bayes...\n","Training KNN...\n","Random Forest - Train Accuracy: 0.9968, Test Accuracy: 0.8622\n","XG Boost - Train Accuracy: 0.9466, Test Accuracy: 0.8822\n","Extra Trees - Train Accuracy: 0.9968, Test Accuracy: 0.7988\n","Linear SVC - Train Accuracy: 0.9065, Test Accuracy: 0.8869\n","Naive Bayes - Train Accuracy: 0.8572, Test Accuracy: 0.8568\n","KNN - Train Accuracy: 0.8930, Test Accuracy: 0.8576\n"]}],"source":["results = train_and_predict_models(train_x_DTM, train_y, test_x_DTM, test_y)\n","\n","# Print the results\n","for model_name, scores in results.items():\n","    print(f\"{model_name} - Train Accuracy: {scores['train_accuracy']:.4f}, Test Accuracy: {scores['test_accuracy']:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"XD6KuxS-F7kr"},"source":["### Selecting LinearSVC as the best model as it has almost similar accuracy for train & test dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QSCTjX0nUni3"},"outputs":[],"source":["## Performing Grid Search cv for Linear SVC\n","\n","## Initializing Linear SVC model\n","LSVC = LinearSVC()\n","\n","# Define a parameter grid for GridSearchCV\n","param_grid = {\n","    'C': [0.01, 0.1, 1, 10, 100],  # Regularization parameter C\n","}\n","\n","# Initialize GridSearchCV\n","grid_search = GridSearchCV(LSVC, param_grid, cv=5)\n","\n","# Training the model using GridSearchCV\n","grid_search.fit(train_x_DTM, train_y)\n","\n","# Get the best parameters and the best estimator\n","best_params = grid_search.best_params_\n","best_estimator = grid_search.best_estimator_\n","\n","# Predicting for Train & Test dataset using the best estimator\n","train_pred_LSVC = best_estimator.predict(train_x_DTM)\n","test_pred_LSVC = best_estimator.predict(test_x_DTM)\n","\n","# Printing classification report for Train & Test\n","print(\"Classification Report for Train Dataset:\")\n","print(classification_report(train_y, train_pred_LSVC))\n","\n","print(\"Classification Report for Test Dataset:\")\n","print(classification_report(test_y, test_pred_LSVC))\n","\n","# Compute accuracy scores for Train & Test\n","train_accuracy = accuracy_score(train_y, train_pred_LSVC)\n","test_accuracy = accuracy_score(test_y, test_pred_LSVC)\n","\n","print(f\"Accuracy Score for Train Dataset: {train_accuracy:.4f}\")\n","print(f\"Accuracy Score for Test Dataset: {test_accuracy:.4f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"TM_xjO2lTAWT"},"source":["### Multinomial Classification Model"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":593,"status":"ok","timestamp":1691417874532,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"RcJXfKNmRH6C"},"outputs":[],"source":["## Getting x & y variables\n","X = data['Review_Text']\n","Y = data['Rating']"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1691417876982,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"XKVD2rMJWrmQ"},"outputs":[],"source":["## Splitting the data intp train & test\n","train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.3, random_state=123)"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":285434,"status":"ok","timestamp":1691418165556,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"k1nTp7dvWrgg"},"outputs":[],"source":["train_X = train_X.apply(lambda x: text_preprocessing(x))\n","test_X = test_X.apply(lambda x: text_preprocessing(x))"]},{"cell_type":"code","execution_count":85,"metadata":{"executionInfo":{"elapsed":519,"status":"ok","timestamp":1691421638578,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"3pGsYFOYTWGW"},"outputs":[],"source":["TFIDF = TfidfVectorizer(analyzer='word',\n","                             token_pattern=r'\\w{1,}',\n","                             ngram_range=(1, 1 ),\n","                             min_df=5,\n","                             max_df=0.9,\n","                             encoding='latin-1' ,\n","                             lowercase = True,\n","                             max_features=1200)\n","train_X_TFIDF = TFIDF.fit_transform(train_X)\n","test_X_TFIDF = TFIDF.transform(test_X)"]},{"cell_type":"code","execution_count":86,"metadata":{"executionInfo":{"elapsed":788,"status":"ok","timestamp":1691421640227,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"ABEBpSjzTWDM"},"outputs":[],"source":["train_X_DTM = pd.DataFrame(train_X_TFIDF.toarray(), columns=TFIDF.get_feature_names_out())\n","test_X_DTM = pd.DataFrame(test_X_TFIDF.toarray(), columns=TFIDF.get_feature_names_out())"]},{"cell_type":"code","execution_count":87,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1691421640228,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"7yaCoQ4SZUbT"},"outputs":[],"source":["def Models(train_x, train_y, test_x, test_y):\n","\n","    # Create the model list\n","    model_list = [\n","        ('Random Forest', RandomForestClassifier()),\n","        ('Extra Trees', ExtraTreeClassifier()),\n","        ('Linear SVC', LinearSVC()),\n","        ('Naive Bayes', MultinomialNB()),\n","        ('KNN', KNeighborsClassifier())\n","    ]\n","\n","    results = {}\n","\n","    for model_name, model in model_list:\n","        print(f\"Training {model_name}...\")\n","        model.fit(train_x, train_y)\n","\n","        # Make predictions on training and testing data\n","        train_pred = model.predict(train_x)\n","        test_pred = model.predict(test_x)\n","\n","        # Calculate accuracy for training and testing data\n","        train_accuracy = accuracy_score(train_y, train_pred)\n","        test_accuracy = accuracy_score(test_y, test_pred)\n","\n","        results[model_name] = {\n","            'train_accuracy': train_accuracy,\n","            'test_accuracy': test_accuracy\n","        }\n","\n","    return results"]},{"cell_type":"code","execution_count":88,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62365,"status":"ok","timestamp":1691421706571,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"RQUS3xXBTWAN","outputId":"52de0172-8c8b-4408-9122-34be093d8843"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Random Forest...\n","Training Extra Trees...\n","Training Linear SVC...\n","Training Naive Bayes...\n","Training KNN...\n","Random Forest - Train Accuracy: 0.9894, Test Accuracy: 0.6037\n","Extra Trees - Train Accuracy: 0.9894, Test Accuracy: 0.4903\n","Linear SVC - Train Accuracy: 0.7089, Test Accuracy: 0.6338\n","Naive Bayes - Train Accuracy: 0.6156, Test Accuracy: 0.6043\n","KNN - Train Accuracy: 0.7007, Test Accuracy: 0.5646\n"]}],"source":["results = Models(train_X_DTM, train_Y, test_X_DTM, test_Y)\n","\n","# Print the results\n","for model_name, scores in results.items():\n","    print(f\"{model_name} - Train Accuracy: {scores['train_accuracy']:.4f}, Test Accuracy: {scores['test_accuracy']:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"5eKUO7MTnZGM"},"source":["### Topic Mining"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":528,"status":"ok","timestamp":1691439456958,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"KOJlp6QWnYCQ"},"outputs":[],"source":["topic_data = data['Review_Text']"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":554,"status":"ok","timestamp":1691439932613,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"ANLQ8htLet4f"},"outputs":[],"source":["#nltk.download('stopwords')\n","#nltk.download('wordnet')\n","#nltk.download('punkt')\n","#nltk.download('averaged_perceptron_tagger')\n","\n","# Function for data preprocessing for topic mining\n","def TP_preprocess_text(text):\n","    text = text.lower()  # Convert to lowercase\n","    text = re.sub(r\"[-()\\\"#/@;:{}`+=~|._!?,'0-9]\", \"\", text)  # Remove punctuation\n","    tokens = word_tokenize(text)  # Tokenization\n","    stop_words = set(stopwords.words('english'))\n","    stop1 = set(list(stop_words)+['always', 'go', 'got', 'could', 'also', 'get', 'us', 'even', 'i', 'm', 'would', 'do', 'go','im','ive'])\n","    tokens = [token for token in tokens if token not in stop1]  # Remove stop words\n","    lemmatizer = WordNetLemmatizer()\n","    tokens = [lemmatizer.lemmatize(token) for token in tokens]  # Lemmatization\n","    return tokens"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":15945,"status":"ok","timestamp":1691439949447,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"Bp64kCW71Jdj"},"outputs":[],"source":["# Preprocess the data\n","processed_data = [TP_preprocess_text(text) for text in topic_data]"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":2292,"status":"ok","timestamp":1691439951722,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"S7G1d2XK1Jan"},"outputs":[],"source":["# Create a dictionary and a document-term matrix\n","dictionary = corpora.Dictionary(processed_data)\n","corpus = [dictionary.doc2bow(text) for text in processed_data]"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":538,"status":"ok","timestamp":1691441063987,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"VQtcX7Hju0kO"},"outputs":[],"source":["# Creating the object for LDA model using gensim library\n","lda_model = gensim.models.ldamodel.LdaModel"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":509101,"status":"ok","timestamp":1691441617118,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"Lvy9YmKqu0ZG","outputId":"fa6170b7-9cf7-49f5-9a4e-1ba3eb7e0c6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Perplexity:  5 -7.084190683059975\n","Perplexity:  6 -7.130388920072971\n","Perplexity:  7 -7.164175977617078\n","Perplexity:  8 -7.230743094984315\n","Perplexity:  9 -7.295040575051355\n","Perplexity:  10 -7.382048052027343\n","Perplexity:  11 -7.468464003112919\n","Perplexity:  12 -7.5571810470579734\n","Perplexity:  13 -7.622245875741787\n","Perplexity:  14 -7.659920018232805\n","Perplexity:  15 -7.713655188327546\n","Perplexity:  16 -7.774748257197995\n","Perplexity:  17 -7.826069483846015\n","Perplexity:  18 -7.876462755266721\n","Perplexity:  19 -7.92670244588422\n"]}],"source":["# Running and Trainign LDA model on the document term matrix.\n","for topics in range(5,20):\n","    lda = lda_model(corpus, num_topics=topics, id2word = dictionary)\n","    print(\"Perplexity: \", topics, lda.log_perplexity(corpus))"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":154709,"status":"ok","timestamp":1691441841282,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"urfmGANK1JXO"},"outputs":[],"source":["# LDA Topic Modeling\n","num_topics = 15  # Specify the number of topics you want to discover\n","Lda_model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10)"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1691441841283,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"mg1o3bdB1JUF","outputId":"931ab62a-4002-49f8-cd61-dd161119d639"},"outputs":[{"name":"stdout","output_type":"stream","text":["Topic 1:\n","dress, wear, love, perfect, flattering, beautiful, comfortable, great, fit, slip, summer, well, wearing, work, cant\n","\n","Topic 2:\n","xd, wore, first, time, received, day, bought, yellow, one, last, week, review, year, ton, already\n","\n","Topic 3:\n","jean, love, great, fit, pant, pair, look, legging, wear, perfect, color, skinny, black, comfortable, bought\n","\n","Topic 4:\n","size, store, small, fit, sale, tried, x, ordered, one, retailer, saw, online, wear, medium, usually\n","\n","Topic 5:\n","wear, comfortable, great, little, super, work, cute, casual, pant, soft, size, fit, enough, like, love\n","\n","Topic 6:\n","&, thread, coral, *, hanging, pear, beach, mother, realized, pink, funny, working, hate, w, impressed\n","\n","Topic 7:\n","size, fit, top, small, like, look, ordered, large, dress, fabric, really, back, run, way, didnt\n","\n","Topic 8:\n","sleeve, blouse, recommend, highly, real, ruffle, sweatshirt, life, dot, sweet, bell, long, detail, flower, panel\n","\n","Topic 9:\n","like, look, fabric, color, picture, much, person, really, photo, model, back, doesnt, feel, make, online\n","\n","Topic 10:\n","top, shirt, love, fit, little, wear, color, back, white, nice, size, like, fabric, soft, cute\n","\n","Topic 11:\n","length, waist, petite, skirt, short, fit, long, hit, regular, size, like, knee, ordered, bit, hip\n","\n","Topic 12:\n","wash, washed, dry, top, hand, washing, yet, shirt, havent, wrinkle, clean, tag, running, cold, poor\n","\n","Topic 13:\n","sweater, warm, coat, cardigan, tunic, soft, sleeve, cozy, long, itchy, knit, winter, wool, bulky, like\n","\n","Topic 14:\n","color, love, great, jacket, fit, piece, well, soft, beautiful, fall, quality, nice, skirt, perfect, fabric\n","\n","Topic 15:\n","many, compliment, buy, suit, perfect, fit, gotten, received, bathing, asked, happier, lean, raspberry, sorry, paris\n","\n"]}],"source":["# Print the topics and their top words\n","for topic_id in range(num_topics):\n","    print(f\"Topic {topic_id + 1}:\")\n","    topic_words = Lda_model.show_topic(topic_id, topn=15)\n","    print(\", \".join([word for word, prob in topic_words]))\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TOTQYgCk1JRV"},"outputs":[],"source":["# Get topic distribution for each document\n","doc_topics = [Lda_model.get_document_topics(doc) for doc in corpus]\n","for doc_id, topics in enumerate(doc_topics):\n","    print(f\"Document {doc_id + 1}:\")\n","    for topic_id, prob in topics:\n","        print(f\"Topic {topic_id + 1}: Probability={prob:.4f}\")\n","    print()"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":12411,"status":"ok","timestamp":1691442546440,"user":{"displayName":"priyanshu singh","userId":"06582038122042461530"},"user_tz":-330},"id":"nFl2taAi1JLD","outputId":"a49a0cdd-a65a-44cc-e296-1d6e6bf8c702"},"outputs":[{"data":{"text/html":["\n","\n","  <div id=\"df-54488bde-3fa6-4cd8-b101-19d67315c86c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text Review</th>\n","      <th>Dominant Theme</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Absolutely wonderful - silky and sexy and comf...</td>\n","      <td>Dress and Summer Fashion</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n","      <td>Shopping Experiences</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I had such high hopes for this dress and reall...</td>\n","      <td>Sizing and Fit</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n","      <td>Quality and Jackets</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>This shirt is very flattering to all due to th...</td>\n","      <td>Shirts and Tops</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>23481</th>\n","      <td>I was very happy to snag this dress at such a ...</td>\n","      <td>Dress and Summer Fashion</td>\n","    </tr>\n","    <tr>\n","      <th>23482</th>\n","      <td>It reminds me of maternity clothes. soft, stre...</td>\n","      <td>Sizing and Fit</td>\n","    </tr>\n","    <tr>\n","      <th>23483</th>\n","      <td>This fit well, but the top was very see throug...</td>\n","      <td>Shopping Experiences</td>\n","    </tr>\n","    <tr>\n","      <th>23484</th>\n","      <td>I bought this dress for a wedding i have this ...</td>\n","      <td>Sizing and Fit</td>\n","    </tr>\n","    <tr>\n","      <th>23485</th>\n","      <td>This dress in a lovely platinum is feminine an...</td>\n","      <td>Dress and Summer Fashion</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>23486 rows Ã— 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54488bde-3fa6-4cd8-b101-19d67315c86c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-5babefbb-374b-409e-b2e1-149dbdd7102c\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5babefbb-374b-409e-b2e1-149dbdd7102c')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-5babefbb-374b-409e-b2e1-149dbdd7102c button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-54488bde-3fa6-4cd8-b101-19d67315c86c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-54488bde-3fa6-4cd8-b101-19d67315c86c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"],"text/plain":["                                             Text Review  \\\n","0      Absolutely wonderful - silky and sexy and comf...   \n","1      Love this dress!  it's sooo pretty.  i happene...   \n","2      I had such high hopes for this dress and reall...   \n","3      I love, love, love this jumpsuit. it's fun, fl...   \n","4      This shirt is very flattering to all due to th...   \n","...                                                  ...   \n","23481  I was very happy to snag this dress at such a ...   \n","23482  It reminds me of maternity clothes. soft, stre...   \n","23483  This fit well, but the top was very see throug...   \n","23484  I bought this dress for a wedding i have this ...   \n","23485  This dress in a lovely platinum is feminine an...   \n","\n","                 Dominant Theme  \n","0      Dress and Summer Fashion  \n","1          Shopping Experiences  \n","2                Sizing and Fit  \n","3           Quality and Jackets  \n","4               Shirts and Tops  \n","...                         ...  \n","23481  Dress and Summer Fashion  \n","23482            Sizing and Fit  \n","23483      Shopping Experiences  \n","23484            Sizing and Fit  \n","23485  Dress and Summer Fashion  \n","\n","[23486 rows x 2 columns]"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["# Predefined themes based on top words of each topic\n","themes = [\n","    \"Dress and Summer Fashion\",\n","    \"Recent Purchases and Reviews\",\n","    \"Jeans and Pants\",\n","    \"Shopping Experiences\",\n","    \"Casual and Comfortable Wear\",\n","    \"Unique and Quirky Items\",\n","    \"Sizing and Fit\",\n","    \"Blouses and Tops\",\n","    \"Online Shopping Experience\",\n","    \"Shirts and Tops\",\n","    \"Length and Fit of Skirts\",\n","    \"Clothing Care and Washing\",\n","    \"Sweaters and Coats\",\n","    \"Quality and Jackets\",\n","    \"Compliments and Positive Feedback\",\n","]\n","\n","# Function to get the dominant theme and its probability for each document\n","def get_dominant_theme(lda_model, doc_term_matrix, themes):\n","    dominant_themes = []\n","    for doc in doc_term_matrix:\n","        topic_probs = lda_model.get_document_topics(doc, minimum_probability=0.0)\n","        dominant_topic = max(topic_probs, key=lambda x: x[1])[0]\n","        dominant_themes.append(themes[dominant_topic])\n","    return dominant_themes\n","\n","# Get the dominant theme for each document\n","dominant_themes = get_dominant_theme(Lda_model, corpus, themes)\n","\n","# Create a DataFrame with the original text reviews and their corresponding dominant themes\n","df = pd.DataFrame({'Text Review': topic_data, 'Dominant Theme': dominant_themes})\n","\n","# Print the DataFrame to see the results\n","df\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMHCadDEyKPAnWTn4gFItsT","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
